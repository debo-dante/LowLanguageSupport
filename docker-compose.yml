version: '3.8'

services:
  nlp-app:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: indian-language-nlp
    volumes:
      # Mount source code for development
      - ./src:/app/src
      - ./notebooks:/app/notebooks
      - ./configs:/app/configs
      - ./scripts:/app/scripts
      - ./tests:/app/tests
      # Mount data directories (created by Dockerfile)
      - nlp-data:/app/data
      # Mount outputs and models for persistence
      - nlp-outputs:/app/outputs
      - nlp-models:/app/models
    ports:
      - "8888:8888"  # Jupyter notebook
      - "6006:6006"  # TensorBoard
    environment:
      - PYTHONUNBUFFERED=1
      - WANDB_API_KEY=${WANDB_API_KEY:-}
    command: bash -c "jupyter notebook --ip=0.0.0.0 --port=8888 --no-browser --allow-root"
    stdin_open: true
    tty: true

  # Optional: Service for training with GPU support
  nlp-train:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: indian-language-nlp-train
    volumes:
      - ./src:/app/src
      - ./configs:/app/configs
      # Mount data and models for training
      - nlp-data:/app/data
      - nlp-outputs:/app/outputs
      - nlp-models:/app/models
    environment:
      - PYTHONUNBUFFERED=1
      - WANDB_API_KEY=${WANDB_API_KEY:-}
    command: python -m src.scripts.train
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    profiles:
      - train

# Named volumes for data persistence
volumes:
  nlp-data:
    driver: local
  nlp-outputs:
    driver: local
  nlp-models:
    driver: local
