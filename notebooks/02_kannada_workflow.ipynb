{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kannada Language Processing Workflow\n",
    "\n",
    "This notebook demonstrates the complete workflow for processing Kannada language text using our specialized framework. Kannada (‡≤ï‡≤®‡≥ç‡≤®‡≤°) is a Dravidian language spoken primarily in Karnataka, India.\n",
    "\n",
    "## What you'll learn:\n",
    "1. **Kannada Data Collection** - Gathering text from Kannada sources\n",
    "2. **Script-Specific Preprocessing** - Handling Kannada script nuances\n",
    "3. **Model Training** - Optimizing models for Kannada\n",
    "4. **Evaluation** - Assessing performance on Kannada tasks\n",
    "5. **Cross-lingual Analysis** - Comparing with other Dravidian languages\n",
    "\n",
    "## About Kannada\n",
    "- **Script**: Kannada script (‡≤ï‡≤®‡≥ç‡≤®‡≤° ‡≤≤‡≤ø‡≤™‡≤ø)\n",
    "- **Family**: Dravidian language family\n",
    "- **Speakers**: ~44 million native speakers\n",
    "- **Unicode Range**: U+0C80‚ÄìU+0CFF\n",
    "- **Characteristics**: Rich morphology, agglutinative, complex conjuncts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import Kannada-specific modules\n",
    "from preprocessing.kannada_preprocessor import KannadaPreprocessor\n",
    "from data_collection.kannada_collector import KannadaDataCollector\n",
    "from models import IndianLanguageModel\n",
    "from evaluation import ModelEvaluator\n",
    "\n",
    "# Set up plotting for Kannada text\n",
    "plt.rcParams['font.family'] = ['Noto Sans Kannada', 'Lohit Kannada', 'sans-serif']\n",
    "plt.style.use('default')\n",
    "\n",
    "print(\"‚úÖ ‡≤ï‡≤®‡≥ç‡≤®‡≤° NLP ‡≤µ‡≥ç‡≤Ø‡≤µ‡≤∏‡≥ç‡≤•‡≥Ü ‡≤∏‡≤ø‡≤¶‡≥ç‡≤ß! (Kannada NLP System Ready!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Kannada Data Collection\n",
    "\n",
    "Let's start by collecting Kannada text from various sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Kannada data collector\n",
    "collector = KannadaDataCollector()\n",
    "\n",
    "print(\"üîç ‡≤ï‡≤®‡≥ç‡≤®‡≤° ‡≤¶‡≤§‡≥ç‡≤§‡≤æ‡≤Ç‡≤∂ ‡≤∏‡≤Ç‡≤ó‡≥ç‡≤∞‡≤π‡≤£‡≥Ü ‡≤™‡≥ç‡≤∞‡≤æ‡≤∞‡≤Ç‡≤≠... (Starting Kannada data collection...)\")\n",
    "\n",
    "# For this demo, we'll use sample Kannada texts\n",
    "sample_kannada_texts = [\n",
    "    {\n",
    "        'title': '‡≤ï‡≤®‡≥ç‡≤®‡≤° ‡≤≠‡≤æ‡≤∑‡≥Ü ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤∏‡≤Ç‡≤∏‡≥ç‡≤ï‡≥É‡≤§‡≤ø',\n",
    "        'content': '‡≤ï‡≤®‡≥ç‡≤®‡≤° ‡≤≠‡≤æ‡≤∑‡≥Ü‡≤Ø‡≥Å ‡≤¶‡≥ç‡≤∞‡≤æ‡≤µ‡≤ø‡≤° ‡≤≠‡≤æ‡≤∑‡≤æ ‡≤ï‡≥Å‡≤ü‡≥Å‡≤Ç‡≤¨‡≤¶ ‡≤í‡≤Ç‡≤¶‡≥Å ‡≤™‡≥ç‡≤∞‡≤Æ‡≥Å‡≤ñ ‡≤≠‡≤æ‡≤∑‡≥Ü‡≤Ø‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü. ‡≤á‡≤¶‡≥Å ‡≤ï‡≤∞‡≥ç‡≤®‡≤æ‡≤ü‡≤ï ‡≤∞‡≤æ‡≤ú‡≥ç‡≤Ø‡≤¶ ‡≤Ö‡≤ß‡≤ø‡≤ï‡≥É‡≤§ ‡≤≠‡≤æ‡≤∑‡≥Ü‡≤Ø‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤∏‡≥Å‡≤Æ‡≤æ‡≤∞‡≥Å ‡≥™.‡≥™ ‡≤ï‡≥ã‡≤ü‡≤ø ‡≤ú‡≤®‡≤∞‡≥Å ‡≤Æ‡≤æ‡≤§‡≤®‡≤æ‡≤°‡≥Å‡≤§‡≥ç‡≤§‡≤æ‡≤∞‡≥Ü. ‡≤ï‡≤®‡≥ç‡≤®‡≤° ‡≤∏‡≤æ‡≤π‡≤ø‡≤§‡≥ç‡≤Ø‡≤µ‡≥Å ‡≤∏‡≤æ‡≤µ‡≤ø‡≤∞‡≤æ‡≤∞‡≥Å ‡≤µ‡≤∞‡≥ç‡≤∑‡≤ó‡≤≥ ‡≤á‡≤§‡≤ø‡≤π‡≤æ‡≤∏‡≤µ‡≤®‡≥ç‡≤®‡≥Å ‡≤π‡≥ä‡≤Ç‡≤¶‡≤ø‡≤¶‡≥Ü.',\n",
    "        'source': '‡≤ï‡≤®‡≥ç‡≤®‡≤° ‡≤™‡≥ç‡≤∞‡≤≠',\n",
    "        'category': 'culture'\n",
    "    },\n",
    "    {\n",
    "        'title': '‡≤¨‡≥Ü‡≤Ç‡≤ó‡≤≥‡≥Ç‡≤∞‡≤ø‡≤® ‡≤§‡≤Ç‡≤§‡≥ç‡≤∞‡≤ú‡≥ç‡≤û‡≤æ‡≤® ‡≤â‡≤¶‡≥ç‡≤Ø‡≤Æ',\n",
    "        'content': '‡≤¨‡≥Ü‡≤Ç‡≤ó‡≤≥‡≥Ç‡≤∞‡≥Å ‡≤≠‡≤æ‡≤∞‡≤§‡≤¶ ‡≤§‡≤Ç‡≤§‡≥ç‡≤∞‡≤ú‡≥ç‡≤û‡≤æ‡≤® ‡≤∞‡≤æ‡≤ú‡≤ß‡≤æ‡≤®‡≤ø ‡≤é‡≤Ç‡≤¶‡≥Å ‡≤π‡≥Ü‡≤∏‡≤∞‡≥Å‡≤µ‡≤æ‡≤∏‡≤ø‡≤Ø‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü. ‡≤á‡≤≤‡≥ç‡≤≤‡≤ø ‡≤Ö‡≤®‡≥á‡≤ï ‡≤¨‡≤π‡≥Å‡≤∞‡≤æ‡≤∑‡≥ç‡≤ü‡≥ç‡≤∞‡≥Ä‡≤Ø ‡≤ï‡≤Ç‡≤™‡≤®‡≤ø‡≤ó‡≤≥‡≥Å ‡≤§‡≤Æ‡≥ç‡≤Æ ‡≤ï‡≤ö‡≥á‡≤∞‡≤ø‡≤ó‡≤≥‡≤®‡≥ç‡≤®‡≥Å ‡≤∏‡≥ç‡≤•‡≤æ‡≤™‡≤ø‡≤∏‡≤ø‡≤¶‡≥ç‡≤¶‡≤æ‡≤∞‡≥Ü. ‡≤ï‡≥É‡≤§‡≥ç‡≤∞‡≤ø‡≤Æ ‡≤¨‡≥Å‡≤¶‡≥ç‡≤ß‡≤ø‡≤Æ‡≤§‡≥ç‡≤§‡≥Ü, ‡≤Ø‡≤Ç‡≤§‡≥ç‡≤∞ ‡≤ï‡≤≤‡≤ø‡≤ï‡≥Ü ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤°‡≥á‡≤ü‡≤æ ‡≤µ‡≤ø‡≤ú‡≥ç‡≤û‡≤æ‡≤®‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø ‡≤á‡≤≤‡≥ç‡≤≤‡≤ø‡≤® ‡≤ï‡≤Ç‡≤™‡≤®‡≤ø‡≤ó‡≤≥‡≥Å ‡≤Æ‡≥Å‡≤Ç‡≤ö‡≥Ç‡≤£‡≤ø‡≤Ø‡≤≤‡≥ç‡≤≤‡≤ø‡≤µ‡≥Ü.',\n",
    "        'source': '‡≤™‡≥ç‡≤∞‡≤ú‡≤æ‡≤µ‡≤æ‡≤£‡≤ø',\n",
    "        'category': 'technology'\n",
    "    },\n",
    "    {\n",
    "        'title': '‡≤ï‡≤∞‡≥ç‡≤®‡≤æ‡≤ü‡≤ï‡≤¶ ‡≤™‡≤∞‡≤Ç‡≤™‡≤∞‡≥Ü',\n",
    "        'content': '‡≤ï‡≤∞‡≥ç‡≤®‡≤æ‡≤ü‡≤ï‡≤µ‡≥Å ‡≤∂‡≥ç‡≤∞‡≥Ä‡≤Æ‡≤Ç‡≤§‡≤µ‡≤æ‡≤¶ ‡≤∏‡≤æ‡≤Ç‡≤∏‡≥ç‡≤ï‡≥É‡≤§‡≤ø‡≤ï ‡≤™‡≤∞‡≤Ç‡≤™‡≤∞‡≥Ü‡≤Ø‡≤®‡≥ç‡≤®‡≥Å ‡≤π‡≥ä‡≤Ç‡≤¶‡≤ø‡≤¶‡≥Ü. ‡≤π‡≤Ç‡≤™‡≤ø, ‡≤Æ‡≥à‡≤∏‡≥Ç‡≤∞‡≥Å, ‡≤¨‡≤æ‡≤¶‡≤æ‡≤Æ‡≤ø ‡≤Æ‡≥Å‡≤Ç‡≤§‡≤æ‡≤¶ ‡≤∏‡≥ç‡≤•‡≤≥‡≤ó‡≤≥‡≥Å ‡≤ê‡≤§‡≤ø‡≤π‡≤æ‡≤∏‡≤ø‡≤ï ‡≤Æ‡≤π‡≤§‡≥ç‡≤µ‡≤µ‡≤®‡≥ç‡≤®‡≥Å ‡≤π‡≥ä‡≤Ç‡≤¶‡≤ø‡≤µ‡≥Ü. ‡≤Ø‡≤ï‡≥ç‡≤∑‡≤ó‡≤æ‡≤®, ‡≤ï‡≤∞‡≥ç‡≤®‡≤æ‡≤ü‡≤ï ‡≤∏‡≤Ç‡≤ó‡≥Ä‡≤§, ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤≠‡≤∞‡≤§‡≤®‡≤æ‡≤ü‡≥ç‡≤Ø ‡≤á‡≤≤‡≥ç‡≤≤‡≤ø‡≤® ‡≤™‡≥ç‡≤∞‡≤Æ‡≥Å‡≤ñ ‡≤ï‡≤≤‡≤æ ‡≤™‡≥ç‡≤∞‡≤ï‡≤æ‡≤∞‡≤ó‡≤≥‡≤æ‡≤ó‡≤ø‡≤µ‡≥Ü.',\n",
    "        'source': '‡≤â‡≤¶‡≤Ø‡≤µ‡≤æ‡≤£‡≤ø',\n",
    "        'category': 'heritage'\n",
    "    },\n",
    "    {\n",
    "        'title': '‡≤Ü‡≤∞‡≥ã‡≤ó‡≥ç‡≤Ø ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤Ü‡≤Ø‡≥Å‡≤∞‡≥ç‡≤µ‡≥á‡≤¶',\n",
    "        'content': '‡≤Ü‡≤Ø‡≥Å‡≤∞‡≥ç‡≤µ‡≥á‡≤¶‡≤µ‡≥Å ‡≤≠‡≤æ‡≤∞‡≤§‡≤¶ ‡≤™‡≥ç‡≤∞‡≤æ‡≤ö‡≥Ä‡≤® ‡≤µ‡≥à‡≤¶‡≥ç‡≤Ø ‡≤∂‡≤æ‡≤∏‡≥ç‡≤§‡≥ç‡≤∞‡≤µ‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü. ‡≤ï‡≤∞‡≥ç‡≤®‡≤æ‡≤ü‡≤ï‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø ‡≤Ö‡≤®‡≥á‡≤ï ‡≤Ü‡≤Ø‡≥Å‡≤∞‡≥ç‡≤µ‡≥á‡≤¶ ‡≤ï‡≤æ‡≤≤‡≥á‡≤ú‡≥Å‡≤ó‡≤≥‡≥Å ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤Ü‡≤∏‡≥ç‡≤™‡≤§‡≥ç‡≤∞‡≥Ü‡≤ó‡≤≥‡≤ø‡≤µ‡≥Ü. ‡≤™‡≥ç‡≤∞‡≤ï‡≥É‡≤§‡≤ø‡≤Ø ‡≤î‡≤∑‡≤ß‡≤ø‡≤ó‡≤≥‡≥Å ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤Ø‡≥ã‡≤ó‡≤¶ ‡≤Æ‡≥Ç‡≤≤‡≤ï ‡≤Ü‡≤∞‡≥ã‡≤ó‡≥ç‡≤Ø‡≤µ‡≤®‡≥ç‡≤®‡≥Å ‡≤ï‡≤æ‡≤™‡≤æ‡≤°‡≥Å‡≤µ ‡≤∏‡≤Ç‡≤™‡≥ç‡≤∞‡≤¶‡≤æ‡≤Ø‡≤µ‡≤ø‡≤¶‡≥Ü.',\n",
    "        'source': '‡≤µ‡≤ø‡≤ú‡≤Ø ‡≤ï‡≤∞‡≥ç‡≤®‡≤æ‡≤ü‡≤ï',\n",
    "        'category': 'health'\n",
    "    },\n",
    "    {\n",
    "        'title': '‡≤ï‡≤∞‡≥ç‡≤®‡≤æ‡≤ü‡≤ï‡≤¶ ‡≤ï‡≥É‡≤∑‡≤ø',\n",
    "        'content': '‡≤ï‡≤∞‡≥ç‡≤®‡≤æ‡≤ü‡≤ï ‡≤∞‡≤æ‡≤ú‡≥ç‡≤Ø‡≤µ‡≥Å ‡≤ï‡≥É‡≤∑‡≤ø‡≤Ø‡≤≤‡≥ç‡≤≤‡≤ø ‡≤™‡≥ç‡≤∞‡≤Æ‡≥Å‡≤ñ ‡≤∏‡≥ç‡≤•‡≤æ‡≤® ‡≤π‡≥ä‡≤Ç‡≤¶‡≤ø‡≤¶‡≥Ü. ‡≤á‡≤≤‡≥ç‡≤≤‡≤ø ‡≤Ö‡≤ï‡≥ç‡≤ï‡≤ø, ‡≤∞‡≤æ‡≤ó‡≤ø, ‡≤∏‡≤ï‡≥ç‡≤ï‡≤∞‡≥Ü ‡≤ï‡≤¨‡≥ç‡≤¨‡≥Å, ‡≤ï‡≤æ‡≤´‡≤ø ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤Æ‡≥Ü‡≤£‡≤∏‡≤ø‡≤®‡≤ï‡≤æ‡≤Ø‡≤ø ‡≤¨‡≥Ü‡≤≥‡≥Ü‡≤Ø‡≥Å‡≤§‡≥ç‡≤§‡≤¶‡≥Ü. ‡≤ï‡≥ä‡≤°‡≤ó‡≥Å ‡≤ú‡≤ø‡≤≤‡≥ç‡≤≤‡≥Ü‡≤Ø‡≥Å ‡≤ï‡≤æ‡≤´‡≤ø ‡≤â‡≤§‡≥ç‡≤™‡≤æ‡≤¶‡≤®‡≥Ü‡≤ó‡≥Ü ‡≤™‡≥ç‡≤∞‡≤∏‡≤ø‡≤¶‡≥ç‡≤ß‡≤µ‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü. ‡≤Ü‡≤ß‡≥Å‡≤®‡≤ø‡≤ï ‡≤ï‡≥É‡≤∑‡≤ø ‡≤§‡≤Ç‡≤§‡≥ç‡≤∞‡≤ó‡≤≥ ‡≤¨‡≤≥‡≤ï‡≥Ü‡≤Ø‡≤ø‡≤Ç‡≤¶ ‡≤â‡≤§‡≥ç‡≤™‡≤æ‡≤¶‡≤®‡≥Ü ‡≤π‡≥Ü‡≤ö‡≥ç‡≤ö‡≤æ‡≤ó‡≥Å‡≤§‡≥ç‡≤§‡≤ø‡≤¶‡≥Ü.',\n",
    "        'source': '‡≤∏‡≤Ç‡≤Ø‡≥Å‡≤ï‡≥ç‡≤§ ‡≤ï‡≤∞‡≥ç‡≤®‡≤æ‡≤ü‡≤ï',\n",
    "        'category': 'agriculture'\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "kannada_df = pd.DataFrame(sample_kannada_texts)\n",
    "kannada_df['timestamp'] = pd.Timestamp.now()\n",
    "kannada_df['language'] = 'kn'\n",
    "kannada_df['text_length'] = kannada_df['content'].str.len()\n",
    "kannada_df['word_count'] = kannada_df['content'].str.split().str.len()\n",
    "\n",
    "print(f\"üìä ‡≤∏‡≤Ç‡≤ó‡≥ç‡≤∞‡≤π‡≤£‡≥Ü ‡≤™‡≥Ç‡≤∞‡≥ç‡≤£! (Collection Complete!)\")\n",
    "print(f\"Total articles: {len(kannada_df)}\")\n",
    "print(f\"Average text length: {kannada_df['text_length'].mean():.0f} characters\")\n",
    "print(f\"Total words: {kannada_df['word_count'].sum()}\")\n",
    "\n",
    "# Show sample\n",
    "print(f\"\\nüì∞ ‡≤Æ‡≤æ‡≤¶‡≤∞‡≤ø ‡≤≤‡≥á‡≤ñ‡≤® (Sample Article):\")\n",
    "sample = kannada_df.iloc[0]\n",
    "print(f\"Title: {sample['title']}\")\n",
    "print(f\"Content: {sample['content'][:150]}...\")\n",
    "print(f\"Category: {sample['category']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Kannada Text Preprocessing\n",
    "\n",
    "Now let's preprocess the Kannada text using our specialized preprocessor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Kannada preprocessor\n",
    "preprocessor = KannadaPreprocessor()\n",
    "\n",
    "print(\"üßπ ‡≤ï‡≤®‡≥ç‡≤®‡≤° ‡≤™‡≤æ‡≤†‡≥ç‡≤Ø ‡≤™‡≥ç‡≤∞‡≤ï‡≥ç‡≤∞‡≤ø‡≤Ø‡≥Ü ‡≤™‡≥ç‡≤∞‡≤æ‡≤∞‡≤Ç‡≤≠... (Starting Kannada text processing...)\")\n",
    "\n",
    "# Test with a sample text\n",
    "sample_text = kannada_df.iloc[1]['content']\n",
    "print(f\"\\nüìù ‡≤Æ‡≥Ç‡≤≤ ‡≤™‡≤æ‡≤†‡≥ç‡≤Ø (Original Text):\")\n",
    "print(sample_text)\n",
    "\n",
    "# Clean the text\n",
    "cleaned_text = preprocessor.clean_kannada_text(\n",
    "    sample_text,\n",
    "    normalize_unicode=True,\n",
    "    normalize_digits=True,\n",
    "    handle_virama=True,\n",
    "    preserve_conjuncts=True\n",
    ")\n",
    "\n",
    "print(f\"\\n‚ú® ‡≤∂‡≥Å‡≤¶‡≥ç‡≤ß‡≥Ä‡≤ï‡≤∞‡≤ø‡≤∏‡≤ø‡≤¶ ‡≤™‡≤æ‡≤†‡≥ç‡≤Ø (Cleaned Text):\")\n",
    "print(cleaned_text)\n",
    "\n",
    "# Get detailed statistics\n",
    "stats = preprocessor.get_kannada_text_statistics(sample_text)\n",
    "print(f\"\\nüìä ‡≤™‡≤æ‡≤†‡≥ç‡≤Ø ‡≤Ö‡≤Ç‡≤ï‡≤ø‡≤Ö‡≤Ç‡≤∂‡≤ó‡≤≥‡≥Å (Text Statistics):\")\n",
    "for key, value in stats.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:.3f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# Tokenize words\n",
    "tokens = preprocessor.tokenize_kannada_words(sample_text)\n",
    "print(f\"\\nüî§ ‡≤™‡≤¶ ‡≤µ‡≤ø‡≤≠‡≤ú‡≤®‡≥Ü (Word Tokenization):\")\n",
    "print(f\"Total tokens: {len(tokens)}\")\n",
    "print(f\"First 10 tokens: {tokens[:10]}\")\n",
    "\n",
    "# Morphological analysis of sample words\n",
    "print(f\"\\nüî¨ ‡≤∞‡≥Ç‡≤™‡≤µ‡≤ø‡≤ú‡≥ç‡≤û‡≤æ‡≤® ‡≤µ‡≤ø‡≤∂‡≥ç‡≤≤‡≥á‡≤∑‡≤£‡≥Ü (Morphological Analysis):\")\n",
    "sample_words = ['‡≤ï‡≤Ç‡≤™‡≤®‡≤ø‡≤ó‡≤≥‡≥Å', '‡≤§‡≤Ç‡≤§‡≥ç‡≤∞‡≤ú‡≥ç‡≤û‡≤æ‡≤®', '‡≤∏‡≥ç‡≤•‡≤æ‡≤™‡≤ø‡≤∏‡≤ø‡≤¶‡≥ç‡≤¶‡≤æ‡≤∞‡≥Ü']\n",
    "for word in sample_words:\n",
    "    analysis = preprocessor.analyze_kannada_morphology(word)\n",
    "    print(f\"  {word}: {analysis}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataset Preprocessing\n",
    "\n",
    "Let's preprocess our entire Kannada dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the entire dataset\n",
    "print(\"‚öôÔ∏è ‡≤∏‡≤Ç‡≤™‡≥Ç‡≤∞‡≥ç‡≤£ ‡≤¶‡≤§‡≥ç‡≤§‡≤∏‡≤Æ‡≥Ç‡≤π ‡≤™‡≥ç‡≤∞‡≤ï‡≥ç‡≤∞‡≤ø‡≤Ø‡≥Ü... (Processing entire dataset...)\")\n",
    "\n",
    "# Apply preprocessing to all content\n",
    "processed_df = preprocessor.preprocess_kannada_dataset(\n",
    "    kannada_df.copy(),\n",
    "    text_column='content',\n",
    "    clean_options={\n",
    "        'normalize_unicode': True,\n",
    "        'normalize_digits': True,\n",
    "        'remove_mixed_script': False,\n",
    "        'preserve_conjuncts': True,\n",
    "        'handle_virama': True\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add additional analysis\n",
    "processed_df['cleaned_word_count'] = processed_df['content'].str.split().str.len()\n",
    "processed_df['cleaned_length'] = processed_df['content'].str.len()\n",
    "processed_df['sentences'] = processed_df['content'].apply(\n",
    "    lambda x: len(preprocessor.extract_kannada_sentences(x))\n",
    ")\n",
    "\n",
    "# Validation\n",
    "processed_df['is_valid_kannada'] = processed_df['content'].apply(\n",
    "    lambda x: preprocessor.validate_kannada_text(x, min_kannada_ratio=0.6)\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ ‡≤™‡≥ç‡≤∞‡≤ï‡≥ç‡≤∞‡≤ø‡≤Ø‡≥Ü ‡≤™‡≥Ç‡≤∞‡≥ç‡≤£! (Processing Complete!)\")\n",
    "print(f\"Valid Kannada texts: {processed_df['is_valid_kannada'].sum()}/{len(processed_df)}\")\n",
    "print(f\"Average sentences per text: {processed_df['sentences'].mean():.1f}\")\n",
    "print(f\"Total cleaned words: {processed_df['cleaned_word_count'].sum()}\")\n",
    "\n",
    "# Show processing comparison\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Metric': ['Original Length', 'Cleaned Length', 'Original Words', 'Cleaned Words'],\n",
    "    'Average': [\n",
    "        processed_df['text_length'].mean(),\n",
    "        processed_df['cleaned_length'].mean(), \n",
    "        processed_df['word_count'].mean(),\n",
    "        processed_df['cleaned_word_count'].mean()\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(f\"\\nüìà ‡≤™‡≥ç‡≤∞‡≤ï‡≥ç‡≤∞‡≤ø‡≤Ø‡≥Ü ‡≤π‡≥ã‡≤≤‡≤ø‡≤ï‡≥Ü (Processing Comparison):\")\n",
    "print(comparison_df.round(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Kannada Language Model Training\n",
    "\n",
    "Let's create and configure a language model optimized for Kannada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Kannada-optimized model\n",
    "print(\"ü§ñ ‡≤ï‡≤®‡≥ç‡≤®‡≤° ‡≤≠‡≤æ‡≤∑‡≤æ ‡≤Æ‡≤æ‡≤¶‡≤∞‡≤ø ‡≤Ü‡≤∞‡≤Ç‡≤≠... (Initializing Kannada language model...)\")\n",
    "\n",
    "kannada_model = IndianLanguageModel(\n",
    "    language='kn',\n",
    "    model_type='bert',\n",
    "    vocab_size=32000,  # Optimized for Kannada\n",
    "    hidden_size=768,\n",
    "    num_hidden_layers=8,  # Smaller for demo\n",
    "    num_attention_heads=12,\n",
    "    max_position_embeddings=1024,  # Longer sequences for Kannada\n",
    "    dropout_prob=0.1\n",
    ")\n",
    "\n",
    "print(\"‚úÖ ‡≤Æ‡≤æ‡≤¶‡≤∞‡≤ø ‡≤∏‡≤ø‡≤¶‡≥ç‡≤ß! (Model Ready!)\")\n",
    "\n",
    "# Get model information\n",
    "param_count = kannada_model.get_parameter_count()\n",
    "print(f\"\\nüìä ‡≤Æ‡≤æ‡≤¶‡≤∞‡≤ø ‡≤Æ‡≤æ‡≤π‡≤ø‡≤§‡≤ø (Model Information):\")\n",
    "for component, count in param_count.items():\n",
    "    print(f\"  {component}: {count:,} parameters\")\n",
    "\n",
    "print(f\"\\nüéØ Total parameters: {param_count['total']:,}\")\n",
    "\n",
    "# Test embeddings with Kannada sentences\n",
    "test_sentences = [\n",
    "    \"‡≤ï‡≤®‡≥ç‡≤®‡≤° ‡≤≠‡≤æ‡≤∑‡≥Ü ‡≤¨‡≤π‡≤≥ ‡≤∏‡≥Å‡≤Ç‡≤¶‡≤∞‡≤µ‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü.\",\n",
    "    \"‡≤¨‡≥Ü‡≤Ç‡≤ó‡≤≥‡≥Ç‡≤∞‡≥Å ‡≤§‡≤Ç‡≤§‡≥ç‡≤∞‡≤ú‡≥ç‡≤û‡≤æ‡≤® ‡≤®‡≤ó‡≤∞‡≤µ‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü.\", \n",
    "    \"‡≤®‡≤æ‡≤µ‡≥Å ‡≤ï‡≥É‡≤§‡≥ç‡≤∞‡≤ø‡≤Æ ‡≤¨‡≥Å‡≤¶‡≥ç‡≤ß‡≤ø‡≤Æ‡≤§‡≥ç‡≤§‡≥Ü‡≤Ø‡≤®‡≥ç‡≤®‡≥Å ‡≤Ö‡≤ß‡≥ç‡≤Ø‡≤Ø‡≤® ‡≤Æ‡≤æ‡≤°‡≥Å‡≤§‡≥ç‡≤§‡≤ø‡≤¶‡≥ç‡≤¶‡≥á‡≤µ‡≥Ü.\",\n",
    "    \"‡≤ï‡≤∞‡≥ç‡≤®‡≤æ‡≤ü‡≤ï‡≤¶ ‡≤∏‡≤Ç‡≤∏‡≥ç‡≤ï‡≥É‡≤§‡≤ø ‡≤∂‡≥ç‡≤∞‡≥Ä‡≤Æ‡≤Ç‡≤§‡≤µ‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü.\"\n",
    "]\n",
    "\n",
    "print(f\"\\nüß† ‡≤≠‡≤æ‡≤∑‡≤æ ‡≤Æ‡≤æ‡≤¶‡≤∞‡≤ø ‡≤™‡≤∞‡≥Ä‡≤ï‡≥ç‡≤∑‡≥Ü (Language Model Testing):\")\n",
    "embeddings = kannada_model.get_embeddings(test_sentences, language='kn')\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "print(f\"Sample embedding (first 5 dims): {embeddings[0][:5].numpy()}\")\n",
    "\n",
    "# Calculate similarities between sentences\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarities = cosine_similarity(embeddings)\n",
    "\n",
    "print(f\"\\nüîÑ ‡≤µ‡≤æ‡≤ï‡≥ç‡≤Ø ‡≤∏‡≤æ‡≤Æ‡≥ç‡≤Ø‡≤§‡≥Ü‡≤ó‡≤≥‡≥Å (Sentence Similarities):\")\n",
    "for i, sent1 in enumerate(test_sentences):\n",
    "    for j, sent2 in enumerate(test_sentences[i+1:], i+1):\n",
    "        sim = similarities[i][j]\n",
    "        print(f\"  {sim:.3f}: '{sent1}' ‚Üî '{sent2}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation on Kannada Tasks\n",
    "\n",
    "Let's evaluate our model's performance on various Kannada NLP tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize evaluator for Kannada\n",
    "evaluator = ModelEvaluator(\n",
    "    model=kannada_model,\n",
    "    language='kn',\n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "print(\"üìä ‡≤ï‡≤®‡≥ç‡≤®‡≤° ‡≤Æ‡≤æ‡≤¶‡≤∞‡≤ø ‡≤Æ‡≥å‡≤≤‡≥ç‡≤Ø‡≤Æ‡≤æ‡≤™‡≤®... (Kannada Model Evaluation...)\")\n",
    "\n",
    "# Create evaluation dataset from our processed texts\n",
    "eval_texts = processed_df['content'].tolist()\n",
    "eval_categories = processed_df['category'].tolist()\n",
    "\n",
    "# Create label mapping for categories\n",
    "category_to_label = {cat: idx for idx, cat in enumerate(set(eval_categories))}\n",
    "label_to_category = {v: k for k, v in category_to_label.items()}\n",
    "eval_labels = [category_to_label[cat] for cat in eval_categories]\n",
    "\n",
    "print(f\"üìã ‡≤Æ‡≥å‡≤≤‡≥ç‡≤Ø‡≤Æ‡≤æ‡≤™‡≤® ‡≤¶‡≤§‡≥ç‡≤§‡≤∏‡≤Æ‡≥Ç‡≤π (Evaluation Dataset):\")\n",
    "print(f\"  Texts: {len(eval_texts)}\")\n",
    "print(f\"  Categories: {list(category_to_label.keys())}\")\n",
    "print(f\"  Labels: {eval_labels}\")\n",
    "\n",
    "# Text classification evaluation\n",
    "print(f\"\\nüéØ ‡≤™‡≤æ‡≤†‡≥ç‡≤Ø ‡≤µ‡≤∞‡≥ç‡≤ó‡≥Ä‡≤ï‡≤∞‡≤£ ‡≤Æ‡≥å‡≤≤‡≥ç‡≤Ø‡≤Æ‡≤æ‡≤™‡≤® (Text Classification Evaluation):\")\n",
    "classification_results = evaluator.evaluate_text_classification(\n",
    "    texts=eval_texts,\n",
    "    labels=eval_labels,\n",
    "    task_name=\"kannada_category_classification\"\n",
    ")\n",
    "\n",
    "print(f\"Classification Results:\")\n",
    "for metric, value in classification_results.items():\n",
    "    if isinstance(value, (int, float)):\n",
    "        print(f\"  {metric}: {value:.4f}\")\n",
    "    elif metric not in ['classification_report']:\n",
    "        print(f\"  {metric}: {value}\")\n",
    "\n",
    "# Semantic similarity evaluation\n",
    "print(f\"\\nüîÑ ‡≤Ö‡≤∞‡≥ç‡≤•‡≤ó‡≤§ ‡≤∏‡≤æ‡≤Æ‡≥ç‡≤Ø‡≤§‡≥Ü ‡≤Æ‡≥å‡≤≤‡≥ç‡≤Ø‡≤Æ‡≤æ‡≤™‡≤® (Semantic Similarity Evaluation):\")\n",
    "\n",
    "# Create pairs of similar and dissimilar Kannada sentences\n",
    "similarity_pairs = [\n",
    "    (\"‡≤ï‡≤®‡≥ç‡≤®‡≤° ‡≤≠‡≤æ‡≤∑‡≥Ü ‡≤∏‡≥Å‡≤Ç‡≤¶‡≤∞‡≤µ‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü\", \"‡≤ï‡≤®‡≥ç‡≤®‡≤° ‡≤≠‡≤æ‡≤∑‡≥Ü ‡≤ö‡≥Ü‡≤Ç‡≤¶‡≤µ‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü\"),  # Similar\n",
    "    (\"‡≤¨‡≥Ü‡≤Ç‡≤ó‡≤≥‡≥Ç‡≤∞‡≥Å ‡≤¶‡≥ä‡≤°‡≥ç‡≤° ‡≤®‡≤ó‡≤∞\", \"‡≤¨‡≥Ü‡≤Ç‡≤ó‡≤≥‡≥Ç‡≤∞‡≥Å ‡≤Æ‡≤π‡≤æ‡≤®‡≤ó‡≤∞\"),  # Similar\n",
    "    (\"‡≤§‡≤Ç‡≤§‡≥ç‡≤∞‡≤ú‡≥ç‡≤û‡≤æ‡≤® ‡≤Ö‡≤≠‡≤ø‡≤µ‡≥É‡≤¶‡≥ç‡≤ß‡≤ø\", \"‡≤ï‡≥É‡≤∑‡≤ø ‡≤â‡≤§‡≥ç‡≤™‡≤æ‡≤¶‡≤®‡≥Ü\"),  # Different\n",
    "    (\"‡≤∏‡≤Ç‡≤∏‡≥ç‡≤ï‡≥É‡≤§‡≤ø ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤ï‡≤≤‡≥Ü\", \"‡≤Ü‡≤∞‡≥ã‡≤ó‡≥ç‡≤Ø ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤î‡≤∑‡≤ß‡≤ø\")  # Different\n",
    "]\n",
    "\n",
    "similarity_scores = [0.8, 0.7, 0.2, 0.1]  # Expected similarity scores\n",
    "\n",
    "similarity_results = evaluator.evaluate_semantic_similarity(\n",
    "    text_pairs=similarity_pairs,\n",
    "    similarity_scores=similarity_scores\n",
    ")\n",
    "\n",
    "print(f\"Semantic Similarity Results:\")\n",
    "for metric, value in similarity_results.items():\n",
    "    print(f\"  {metric}: {value:.4f}\")\n",
    "\n",
    "# Show individual pair similarities\n",
    "print(f\"\\nüìù ‡≤µ‡≥ç‡≤Ø‡≤ï‡≥ç‡≤§‡≤ø‡≤ó‡≤§ ‡≤ú‡≥ã‡≤°‡≤ø ‡≤∏‡≤æ‡≤Æ‡≥ç‡≤Ø‡≤§‡≥Ü‡≤ó‡≤≥‡≥Å (Individual Pair Similarities):\")\n",
    "for i, (text1, text2) in enumerate(similarity_pairs):\n",
    "    emb1 = kannada_model.get_embeddings([text1], language='kn')\n",
    "    emb2 = kannada_model.get_embeddings([text2], language='kn')\n",
    "    sim = cosine_similarity(emb1, emb2)[0, 0]\n",
    "    print(f\"  {sim:.3f}: '{text1}' ‚Üî '{text2}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cross-lingual Analysis with Dravidian Languages\n",
    "\n",
    "Let's evaluate cross-lingual capabilities with other Dravidian languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üåç ‡≤¶‡≥ç‡≤∞‡≤æ‡≤µ‡≤ø‡≤° ‡≤≠‡≤æ‡≤∑‡≥Ü‡≤ó‡≤≥ ‡≤Ö‡≤Ç‡≤§‡≤∞‡≥ç-‡≤≠‡≤æ‡≤∑‡≥Ü ‡≤µ‡≤ø‡≤∂‡≥ç‡≤≤‡≥á‡≤∑‡≤£‡≥Ü (Cross-lingual Analysis with Dravidian Languages)\")\n",
    "\n",
    "# Multilingual data with Dravidian languages\n",
    "dravidian_data = {\n",
    "    'kn': {  # Kannada\n",
    "        'texts': [\n",
    "            \"‡≤á‡≤¶‡≥Å ‡≤í‡≤Ç‡≤¶‡≥Å ‡≤ö‡≥Ü‡≤Ç‡≤¶‡≤¶ ‡≤¶‡≤ø‡≤®.\",\n",
    "            \"‡≤®‡≤æ‡≤®‡≥Å ‡≤ï‡≤®‡≥ç‡≤®‡≤° ‡≤≠‡≤æ‡≤∑‡≥Ü‡≤Ø‡≤®‡≥ç‡≤®‡≥Å ‡≤™‡≥ç‡≤∞‡≥Ä‡≤§‡≤ø‡≤∏‡≥Å‡≤§‡≥ç‡≤§‡≥á‡≤®‡≥Ü.\",\n",
    "            \"‡≤§‡≤Ç‡≤§‡≥ç‡≤∞‡≤ú‡≥ç‡≤û‡≤æ‡≤® ‡≤®‡≤Æ‡≥ç‡≤Æ ‡≤≠‡≤µ‡≤ø‡≤∑‡≥ç‡≤Ø.\"\n",
    "        ],\n",
    "        'labels': [1, 1, 1]  # Positive sentiment\n",
    "    },\n",
    "    'ta': {  # Tamil  \n",
    "        'texts': [\n",
    "            \"‡Æá‡Æ§‡ØÅ ‡Æí‡Æ∞‡ØÅ ‡ÆÖ‡Æ¥‡Æï‡Ææ‡Æ© ‡Æ®‡Ææ‡Æ≥‡Øç.\",  # This is a beautiful day\n",
    "            \"‡Æ®‡Ææ‡Æ©‡Øç ‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç ‡ÆÆ‡Øä‡Æ¥‡Æø‡ÆØ‡Øà ‡Æ®‡Øá‡Æö‡Æø‡Æï‡Øç‡Æï‡Æø‡Æ±‡Øá‡Æ©‡Øç.\",  # I love Tamil language\n",
    "            \"‡Æ§‡Øä‡Æ¥‡Æø‡Æ≤‡Øç‡Æ®‡ØÅ‡Æü‡Øç‡Æ™‡ÆÆ‡Øç ‡Æ®‡ÆÆ‡Æ§‡ØÅ ‡Æé‡Æ§‡Æø‡Æ∞‡Øç‡Æï‡Ææ‡Æ≤‡ÆÆ‡Øç.\"  # Technology is our future\n",
    "        ],\n",
    "        'labels': [1, 1, 1]  # Positive sentiment\n",
    "    },\n",
    "    'te': {  # Telugu\n",
    "        'texts': [\n",
    "            \"‡∞á‡∞¶‡∞ø ‡∞í‡∞ï ‡∞Ö‡∞Ç‡∞¶‡∞Æ‡±à‡∞® ‡∞∞‡±ã‡∞ú‡±Å.\",  # This is a beautiful day\n",
    "            \"‡∞®‡±á‡∞®‡±Å ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å ‡∞≠‡∞æ‡∞∑‡∞®‡±Å ‡∞™‡±ç‡∞∞‡±á‡∞Æ‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞®‡±Å.\",  # I love Telugu language  \n",
    "            \"‡∞∏‡∞æ‡∞Ç‡∞ï‡±á‡∞§‡∞ø‡∞ï‡∞§ ‡∞Æ‡∞® ‡∞≠‡∞µ‡∞ø‡∞∑‡±ç‡∞Ø‡∞§‡±ç‡∞§‡±Å.\"  # Technology is our future\n",
    "        ],\n",
    "        'labels': [1, 1, 1]  # Positive sentiment\n",
    "    },\n",
    "    'ml': {  # Malayalam\n",
    "        'texts': [\n",
    "            \"‡¥á‡¥§‡µç ‡¥Æ‡¥®‡µã‡¥π‡¥∞‡¥Æ‡¥æ‡¥Ø ‡¥¶‡¥ø‡¥®‡¥Æ‡¥æ‡¥£‡µç.\",  # This is a beautiful day\n",
    "            \"‡¥û‡¥æ‡µª ‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç ‡¥≠‡¥æ‡¥∑‡¥Ø‡µÜ ‡¥∏‡µç‡¥®‡µá‡¥π‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥®‡µç‡¥®‡µÅ.\",  # I love Malayalam language\n",
    "            \"‡¥∏‡¥æ‡¥ô‡µç‡¥ï‡µá‡¥§‡¥ø‡¥ï‡¥µ‡¥ø‡¥¶‡µç‡¥Ø ‡¥®‡¥Æ‡µç‡¥Æ‡µÅ‡¥ü‡µÜ ‡¥≠‡¥æ‡¥µ‡¥ø‡¥Ø‡¥æ‡¥£‡µç.\"  # Technology is our future\n",
    "        ],\n",
    "        'labels': [1, 1, 1]  # Positive sentiment\n",
    "    }\n",
    "}\n",
    "\n",
    "# Multilingual evaluation\n",
    "multilingual_results = evaluator.evaluate_multilingual_capabilities(dravidian_data)\n",
    "\n",
    "print(f\"\\nüó∫Ô∏è ‡≤¨‡≤π‡≥Å‡≤≠‡≤æ‡≤∑‡≥Ü ‡≤´‡≤≤‡≤ø‡≤§‡≤æ‡≤Ç‡≤∂‡≤ó‡≤≥‡≥Å (Multilingual Results):\")\n",
    "print(f\"  Supported languages: {multilingual_results['supported_languages']}\")\n",
    "print(f\"  Consistency score: {multilingual_results['consistency_score']:.4f}\")\n",
    "print(f\"  Number of languages: {multilingual_results['num_languages']}\")\n",
    "\n",
    "# Language-specific results\n",
    "print(f\"\\nüìä ‡≤≠‡≤æ‡≤∑‡≤æ-‡≤®‡≤ø‡≤∞‡≥ç‡≤¶‡≤ø‡≤∑‡≥ç‡≤ü ‡≤´‡≤≤‡≤ø‡≤§‡≤æ‡≤Ç‡≤∂‡≤ó‡≤≥‡≥Å (Language-specific Results):\")\n",
    "for lang, results in multilingual_results['language_results'].items():\n",
    "    lang_names = {'kn': '‡≤ï‡≤®‡≥ç‡≤®‡≤°', 'ta': '‡≤§‡≤Æ‡≤ø‡≤≥‡≥Å', 'te': '‡≤§‡≥Ü‡≤≤‡≥Å‡≤ó‡≥Å', 'ml': '‡≤Æ‡≤≤‡≤Ø‡≤æ‡≤≥‡≤Ç'}\n",
    "    print(f\"\\n  {lang_names.get(lang, lang).upper()} ({lang}):\")\n",
    "    for metric, value in results.items():\n",
    "        if isinstance(value, (int, float)):\n",
    "            print(f\"    {metric}: {value:.4f}\")\n",
    "        else:\n",
    "            print(f\"    {metric}: {value}\")\n",
    "\n",
    "# Cross-lingual transfer: Kannada ‚Üí Tamil\n",
    "print(f\"\\nüîÑ ‡≤Ö‡≤Ç‡≤§‡≤∞‡≥ç-‡≤≠‡≤æ‡≤∑‡≥Ü ‡≤µ‡≤∞‡≥ç‡≤ó‡≤æ‡≤µ‡≤£‡≥Ü: ‡≤ï‡≤®‡≥ç‡≤®‡≤° ‚Üí ‡≤§‡≤Æ‡≤ø‡≤≥‡≥Å (Cross-lingual Transfer: Kannada ‚Üí Tamil)\")\n",
    "\n",
    "cross_lingual_results = evaluator.evaluate_cross_lingual_transfer(\n",
    "    source_data=dravidian_data['kn'],\n",
    "    target_data=dravidian_data['ta'],\n",
    "    source_lang='kn',\n",
    "    target_lang='ta'\n",
    ")\n",
    "\n",
    "print(f\"Cross-lingual Transfer Results:\")\n",
    "for metric, value in cross_lingual_results.items():\n",
    "    if isinstance(value, (int, float)):\n",
    "        print(f\"  {metric}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"  {metric}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Kannada Text Analysis and Visualization\n",
    "\n",
    "Let's create some visualizations specific to Kannada text analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä ‡≤ï‡≤®‡≥ç‡≤®‡≤° ‡≤™‡≤æ‡≤†‡≥ç‡≤Ø ‡≤µ‡≤ø‡≤∂‡≥ç‡≤≤‡≥á‡≤∑‡≤£‡≥Ü ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å ‡≤¶‡≥É‡≤∂‡≥ç‡≤Ø‡≥Ä‡≤ï‡≤∞‡≤£ (Kannada Text Analysis and Visualization)\")\n",
    "\n",
    "# Analyze character distribution in Kannada texts\n",
    "all_kannada_text = ' '.join(processed_df['content'])\n",
    "char_analysis = {}\n",
    "\n",
    "# Count different types of characters\n",
    "kannada_chars = sum(1 for c in all_kannada_text if 0x0C80 <= ord(c) <= 0x0CFF)\n",
    "latin_chars = sum(1 for c in all_kannada_text if c.isalpha() and ord(c) < 128)\n",
    "digits = sum(1 for c in all_kannada_text if c.isdigit())\n",
    "spaces = sum(1 for c in all_kannada_text if c.isspace())\n",
    "punctuation = sum(1 for c in all_kannada_text if c in '.,!?;:')\n",
    "\n",
    "char_distribution = {\n",
    "    '‡≤ï‡≤®‡≥ç‡≤®‡≤° ‡≤Ö‡≤ï‡≥ç‡≤∑‡≤∞‡≤ó‡≤≥‡≥Å': kannada_chars,\n",
    "    '‡≤≤‡≥ç‡≤Ø‡≤æ‡≤ü‡≤ø‡≤®‡≥ç ‡≤Ö‡≤ï‡≥ç‡≤∑‡≤∞‡≤ó‡≤≥‡≥Å': latin_chars,\n",
    "    '‡≤Ö‡≤Ç‡≤ï‡≥Ü‡≤ó‡≤≥‡≥Å': digits,\n",
    "    '‡≤ñ‡≤æ‡≤≤‡≤ø ‡≤ú‡≤æ‡≤ó‡≤ó‡≤≥‡≥Å': spaces,\n",
    "    '‡≤µ‡≤ø‡≤∞‡≤æ‡≤Æ ‡≤ö‡≤ø‡≤π‡≥ç‡≤®‡≥Ü‡≤ó‡≤≥‡≥Å': punctuation\n",
    "}\n",
    "\n",
    "print(f\"\\nüî§ ‡≤Ö‡≤ï‡≥ç‡≤∑‡≤∞ ‡≤µ‡≤ø‡≤§‡≤∞‡≤£‡≥Ü (Character Distribution):\")\n",
    "for char_type, count in char_distribution.items():\n",
    "    percentage = (count / len(all_kannada_text)) * 100\n",
    "    print(f\"  {char_type}: {count:,} ({percentage:.1f}%)\")\n",
    "\n",
    "# Word length analysis\n",
    "all_words = []\n",
    "for text in processed_df['content']:\n",
    "    words = preprocessor.tokenize_kannada_words(text)\n",
    "    all_words.extend(words)\n",
    "\n",
    "word_lengths = [len(word) for word in all_words]\n",
    "\n",
    "print(f\"\\nüìè ‡≤™‡≤¶ ‡≤â‡≤¶‡≥ç‡≤¶‡≤¶ ‡≤µ‡≤ø‡≤∂‡≥ç‡≤≤‡≥á‡≤∑‡≤£‡≥Ü (Word Length Analysis):\")\n",
    "print(f\"  Total words: {len(all_words):,}\")\n",
    "print(f\"  Average word length: {np.mean(word_lengths):.1f} characters\")\n",
    "print(f\"  Shortest word: {min(all_words, key=len)} ({len(min(all_words, key=len))} chars)\")\n",
    "print(f\"  Longest word: {max(all_words, key=len)} ({len(max(all_words, key=len))} chars)\")\n",
    "\n",
    "# Create visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('‡≤ï‡≤®‡≥ç‡≤®‡≤° ‡≤™‡≤æ‡≤†‡≥ç‡≤Ø ‡≤µ‡≤ø‡≤∂‡≥ç‡≤≤‡≥á‡≤∑‡≤£‡≥Ü (Kannada Text Analysis)', fontsize=16)\n",
    "\n",
    "# Character distribution pie chart\n",
    "axes[0, 0].pie(char_distribution.values(), labels=char_distribution.keys(), autopct='%1.1f%%')\n",
    "axes[0, 0].set_title('‡≤Ö‡≤ï‡≥ç‡≤∑‡≤∞ ‡≤µ‡≤ø‡≤§‡≤∞‡≤£‡≥Ü (Character Distribution)')\n",
    "\n",
    "# Word length histogram\n",
    "axes[0, 1].hist(word_lengths, bins=20, alpha=0.7, color='skyblue')\n",
    "axes[0, 1].set_title('‡≤™‡≤¶ ‡≤â‡≤¶‡≥ç‡≤¶‡≤¶ ‡≤µ‡≤ø‡≤§‡≤∞‡≤£‡≥Ü (Word Length Distribution)')\n",
    "axes[0, 1].set_xlabel('Word Length (characters)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Category distribution\n",
    "category_counts = processed_df['category'].value_counts()\n",
    "axes[1, 0].bar(category_counts.index, category_counts.values)\n",
    "axes[1, 0].set_title('‡≤µ‡≤ø‡≤∑‡≤Ø ‡≤µ‡≤ø‡≤§‡≤∞‡≤£‡≥Ü (Category Distribution)')\n",
    "axes[1, 0].set_xlabel('Category')\n",
    "axes[1, 0].set_ylabel('Count')\n",
    "plt.setp(axes[1, 0].xaxis.get_majorticklabels(), rotation=45)\n",
    "\n",
    "# Text length distribution\n",
    "axes[1, 1].hist(processed_df['cleaned_length'], bins=10, alpha=0.7, color='lightgreen')\n",
    "axes[1, 1].set_title('‡≤™‡≤æ‡≤†‡≥ç‡≤Ø ‡≤â‡≤¶‡≥ç‡≤¶‡≤¶ ‡≤µ‡≤ø‡≤§‡≤∞‡≤£‡≥Ü (Text Length Distribution)')\n",
    "axes[1, 1].set_xlabel('Text Length (characters)')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Most common words\n",
    "from collections import Counter\n",
    "word_freq = Counter(all_words)\n",
    "common_words = word_freq.most_common(10)\n",
    "\n",
    "print(f\"\\nüîù ‡≤∏‡≤æ‡≤Æ‡≤æ‡≤®‡≥ç‡≤Ø ‡≤™‡≤¶‡≤ó‡≤≥‡≥Å (Most Common Words):\")\n",
    "for word, freq in common_words:\n",
    "    print(f\"  {word}: {freq} times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Generate Comprehensive Kannada Report\n",
    "\n",
    "Let's generate a comprehensive evaluation report for our Kannada model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive evaluation report\n",
    "print(\"üìã ‡≤∏‡≤Æ‡≤ó‡≥ç‡≤∞ ‡≤ï‡≤®‡≥ç‡≤®‡≤° ‡≤Æ‡≥å‡≤≤‡≥ç‡≤Ø‡≤Æ‡≤æ‡≤™‡≤® ‡≤µ‡≤∞‡≤¶‡≤ø ‡≤§‡≤Ø‡≤æ‡≤∞‡≤ø‡≤ï‡≥Ü... (Generating Comprehensive Kannada Evaluation Report...)\")\n",
    "\n",
    "report = evaluator.generate_evaluation_report(\n",
    "    output_path='../data/kannada_evaluation_report'\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‡≤ï‡≤®‡≥ç‡≤®‡≤° ‡≤≠‡≤æ‡≤∑‡≤æ ‡≤Æ‡≤æ‡≤¶‡≤∞‡≤ø ‡≤Æ‡≥å‡≤≤‡≥ç‡≤Ø‡≤Æ‡≤æ‡≤™‡≤® ‡≤µ‡≤∞‡≤¶‡≤ø (KANNADA LANGUAGE MODEL EVALUATION REPORT)\")\n",
    "print(\"=\"*80)\n",
    "print(report[:1500] + \"...\" if len(report) > 1500 else report)\n",
    "\n",
    "print(\"\\n‚úÖ ‡≤µ‡≤∞‡≤¶‡≤ø ‡≤â‡≤≥‡≤ø‡≤∏‡≤≤‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü: ../data/kannada_evaluation_report.json ‡≤Æ‡≤§‡≥ç‡≤§‡≥Å .txt ‡≤´‡≥à‡≤≤‡≥ç‚Äå‡≤ó‡≤≥‡≤≤‡≥ç‡≤≤‡≤ø\")\n",
    "print(\"‚úÖ Report saved to: ../data/kannada_evaluation_report.json and .txt files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Kannada Model\n",
    "\n",
    "Finally, let's save our trained Kannada model for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Kannada-optimized model\n",
    "kannada_model_path = '../data/models/kannada/kannada_language_model'\n",
    "\n",
    "print(f\"üíæ ‡≤ï‡≤®‡≥ç‡≤®‡≤° ‡≤Æ‡≤æ‡≤¶‡≤∞‡≤ø‡≤Ø‡≤®‡≥ç‡≤®‡≥Å ‡≤â‡≤≥‡≤ø‡≤∏‡≤≤‡≤æ‡≤ó‡≥Å‡≤§‡≥ç‡≤§‡≤ø‡≤¶‡≥Ü... (Saving Kannada model to: {kannada_model_path})\")\n",
    "\n",
    "try:\n",
    "    kannada_model.save_model(kannada_model_path)\n",
    "    print(\"‚úÖ ‡≤Æ‡≤æ‡≤¶‡≤∞‡≤ø ‡≤Ø‡≤∂‡≤∏‡≥ç‡≤µ‡≤ø‡≤Ø‡≤æ‡≤ó‡≤ø ‡≤â‡≤≥‡≤ø‡≤∏‡≤≤‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü! (Model saved successfully!)\")\n",
    "    \n",
    "    # Test loading the model\n",
    "    print(\"üîÑ ‡≤Æ‡≤æ‡≤¶‡≤∞‡≤ø ‡≤≤‡≥ã‡≤°‡≥ç ‡≤Æ‡≤æ‡≤°‡≥Å‡≤µ‡≤ø‡≤ï‡≥Ü‡≤Ø‡≤®‡≥ç‡≤®‡≥Å ‡≤™‡≤∞‡≥Ä‡≤ï‡≥ç‡≤∑‡≤ø‡≤∏‡≤≤‡≤æ‡≤ó‡≥Å‡≤§‡≥ç‡≤§‡≤ø‡≤¶‡≥Ü... (Testing model loading...)\")\n",
    "    loaded_model = IndianLanguageModel.load_model(kannada_model_path)\n",
    "    print(\"‚úÖ ‡≤Æ‡≤æ‡≤¶‡≤∞‡≤ø ‡≤Ø‡≤∂‡≤∏‡≥ç‡≤µ‡≤ø‡≤Ø‡≤æ‡≤ó‡≤ø ‡≤≤‡≥ã‡≤°‡≥ç ‡≤Ü‡≤ó‡≤ø‡≤¶‡≥Ü! (Model loaded successfully!)\")\n",
    "    \n",
    "    # Verify the loaded model works with Kannada\n",
    "    test_kannada_text = \"‡≤á‡≤¶‡≥Å ‡≤í‡≤Ç‡≤¶‡≥Å ‡≤™‡≤∞‡≥Ä‡≤ï‡≥ç‡≤∑‡≤æ ‡≤µ‡≤æ‡≤ï‡≥ç‡≤Ø‡≤µ‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü.\"  # This is a test sentence\n",
    "    test_embeddings = loaded_model.get_embeddings([test_kannada_text], language='kn')\n",
    "    print(f\"‚úÖ ‡≤≤‡≥ã‡≤°‡≥ç ‡≤Æ‡≤æ‡≤°‡≤ø‡≤¶ ‡≤Æ‡≤æ‡≤¶‡≤∞‡≤ø ‡≤ï‡≤æ‡≤∞‡≥ç‡≤Ø‡≤®‡≤ø‡≤∞‡≥ç‡≤µ‡≤π‡≤ø‡≤∏‡≥Å‡≤§‡≥ç‡≤§‡≤ø‡≤¶‡≥Ü! ‡≤é‡≤Ç‡≤¨‡≥Ü‡≤°‡≤ø‡≤Ç‡≤ó‡≥ç ‡≤Ü‡≤ï‡≤æ‡≤∞: {test_embeddings.shape}\")\n",
    "    print(f\"‚úÖ Loaded model working! Embedding shape: {test_embeddings.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ‡≤Æ‡≤æ‡≤¶‡≤∞‡≤ø ‡≤â‡≤≥‡≤ø‡≤∏‡≥Å‡≤µ‡≤≤‡≥ç‡≤≤‡≤ø/‡≤≤‡≥ã‡≤°‡≥ç ‡≤Æ‡≤æ‡≤°‡≥Å‡≤µ‡≤≤‡≥ç‡≤≤‡≤ø ‡≤¶‡≥ã‡≤∑: {e}\")\n",
    "    print(f\"‚ùå Error saving/loading model: {e}\")\n",
    "\n",
    "# Save the processed dataset too\n",
    "dataset_path = '../data/processed/kannada_dataset.csv'\n",
    "processed_df.to_csv(dataset_path, index=False, encoding='utf-8')\n",
    "print(f\"\\nüíæ ‡≤™‡≥ç‡≤∞‡≤ï‡≥ç‡≤∞‡≤ø‡≤Ø‡≥Ü‡≤ó‡≥ä‡≤≥‡≤ø‡≤∏‡≤ø‡≤¶ ‡≤¶‡≤§‡≥ç‡≤§‡≤∏‡≤Æ‡≥Ç‡≤π ‡≤â‡≤≥‡≤ø‡≤∏‡≤≤‡≤æ‡≤ó‡≤ø‡≤¶‡≥Ü: {dataset_path}\")\n",
    "print(f\"üíæ Processed dataset saved to: {dataset_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‡≤∏‡≤æ‡≤∞‡≤æ‡≤Ç‡≤∂ (Summary)\n",
    "\n",
    "üéâ **‡≤Ö‡≤≠‡≤ø‡≤®‡≤Ç‡≤¶‡≤®‡≥Ü‡≤ó‡≤≥‡≥Å! (Congratulations!)** \n",
    "\n",
    "You've successfully completed the Kannada language processing workflow:\n",
    "\n",
    "### ‡≤™‡≥Ç‡≤∞‡≥ç‡≤£‡≤ó‡≥ä‡≤Ç‡≤° ‡≤ï‡≤æ‡≤∞‡≥ç‡≤Ø‡≤ó‡≤≥‡≥Å (Completed Tasks):\n",
    "\n",
    "1. ‚úÖ **‡≤¶‡≤§‡≥ç‡≤§ ‡≤∏‡≤Ç‡≤ó‡≥ç‡≤∞‡≤π‡≤£‡≥Ü (Data Collection)**: Collected and curated Kannada text from various domains\n",
    "2. ‚úÖ **‡≤™‡≥ç‡≤∞‡≥Ä-‡≤™‡≥ç‡≤∞‡≥ä‡≤∏‡≥Ü‡≤∏‡≤ø‡≤Ç‡≤ó‡≥ç (Preprocessing)**: Applied Kannada-specific text cleaning and normalization\n",
    "3. ‚úÖ **‡≤Æ‡≤æ‡≤¶‡≤∞‡≤ø ‡≤§‡≤∞‡≤¨‡≥á‡≤§‡≤ø (Model Training)**: Configured and initialized model optimized for Kannada\n",
    "4. ‚úÖ **‡≤Æ‡≥å‡≤≤‡≥ç‡≤Ø‡≤Æ‡≤æ‡≤™‡≤® (Evaluation)**: Assessed model performance on Kannada NLP tasks\n",
    "5. ‚úÖ **‡≤Ö‡≤Ç‡≤§‡≤∞‡≥ç-‡≤≠‡≤æ‡≤∑‡≥Ü ‡≤µ‡≤ø‡≤∂‡≥ç‡≤≤‡≥á‡≤∑‡≤£‡≥Ü (Cross-lingual Analysis)**: Compared with other Dravidian languages\n",
    "6. ‚úÖ **‡≤¶‡≥É‡≤∂‡≥ç‡≤Ø‡≥Ä‡≤ï‡≤∞‡≤£ (Visualization)**: Created Kannada text analysis visualizations\n",
    "7. ‚úÖ **‡≤µ‡≤∞‡≤¶‡≤ø ‡≤§‡≤Ø‡≤æ‡≤∞‡≤ø‡≤ï‡≥Ü (Report Generation)**: Generated comprehensive evaluation reports\n",
    "8. ‚úÖ **‡≤Æ‡≤æ‡≤¶‡≤∞‡≤ø ‡≤â‡≤≥‡≤ø‡≤ï‡≥Ü (Model Saving)**: Saved the model for future use\n",
    "\n",
    "### ‡≤Æ‡≥Å‡≤Ç‡≤¶‡≤ø‡≤® ‡≤π‡≤Ç‡≤§‡≤ó‡≤≥‡≥Å (Next Steps):\n",
    "\n",
    "- **‡≤¶‡≥ä‡≤°‡≥ç‡≤° ‡≤¶‡≤§‡≥ç‡≤§‡≤∏‡≤Æ‡≥Ç‡≤π‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø ‡≤§‡≤∞‡≤¨‡≥á‡≤§‡≤ø**: Train on larger Kannada datasets\n",
    "- **‡≤µ‡≤ø‡≤∂‡≥á‡≤∑ ‡≤ï‡≤æ‡≤∞‡≥ç‡≤Ø‡≤ó‡≤≥‡≥Å**: Implement specific tasks like POS tagging, NER for Kannada\n",
    "- **‡≤∏‡≤æ‡≤π‡≤ø‡≤§‡≥ç‡≤Ø ‡≤µ‡≤ø‡≤∂‡≥ç‡≤≤‡≥á‡≤∑‡≤£‡≥Ü**: Analyze classical Kannada literature\n",
    "- **‡≤ï‡≤®‡≥ç‡≤®‡≤°-‡≤á‡≤Ç‡≤ó‡≥ç‡≤≤‡≤ø‡≤∑‡≥ç ‡≤Ö‡≤®‡≥Å‡≤µ‡≤æ‡≤¶**: Develop translation models\n",
    "- **‡≤ß‡≥ç‡≤µ‡≤®‡≤ø ‡≤∏‡≤Ç‡≤∏‡≥ç‡≤ï‡≤∞‡≤£‡≥Ü**: Integrate with Kannada speech processing\n",
    "\n",
    "### ‡≤∏‡≤Ç‡≤™‡≤®‡≥ç‡≤Æ‡≥Ç‡≤≤‡≤ó‡≤≥‡≥Å (Resources):\n",
    "\n",
    "- [‡≤ï‡≤®‡≥ç‡≤®‡≤° ‡≤∏‡≤æ‡≤π‡≤ø‡≤§‡≥ç‡≤Ø ‡≤™‡≤∞‡≤ø‡≤∑‡≤§‡≥ç (Kannada Sahitya Parishat)](https://kannadasahityaparishat.org/)\n",
    "- [‡≤ï‡≤®‡≥ç‡≤®‡≤° ‡≤µ‡≤ø‡≤ï‡≤ø‡≤™‡≥Ä‡≤°‡≤ø‡≤Ø‡≤æ (Kannada Wikipedia)](https://kn.wikipedia.org/)\n",
    "- [AI4Bharat Kannada Resources](https://ai4bharat.org/)\n",
    "- [IndicNLP Library](https://github.com/anoopkunchukuttan/indic_nlp_library)\n",
    "\n",
    "---\n",
    "\n",
    "**‡≤ï‡≤®‡≥ç‡≤®‡≤° ‡≤≠‡≤æ‡≤∑‡≥Ü‡≤Ø ‡≤°‡≤ø‡≤ú‡≤ø‡≤ü‡≤≤‡≥ç ‡≤≠‡≤µ‡≤ø‡≤∑‡≥ç‡≤Ø‡≤¶ ‡≤®‡≤ø‡≤∞‡≥ç‡≤Æ‡≤æ‡≤£‡≤¶‡≤≤‡≥ç‡≤≤‡≤ø ‡≤™‡≤æ‡≤≤‡≥ç‡≤ó‡≥ä‡≤≥‡≥ç‡≤≥‡≤ø!** üåü\n",
    "\n",
    "**Join in building the digital future of the Kannada language!** üáÆüá≥‚ú®"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}